{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please install the 'pandas' package to use this function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_pandas_helpers.py:32\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     pandas_import_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m      3\u001b[0m client \u001b[38;5;241m=\u001b[39m bigquery\u001b[38;5;241m.\u001b[39mClient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransfusion-reactions\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#put your project id here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mWITH first_admission_time AS\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m(\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m  SELECT\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124mfrom age\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124mgroup by age_group, gender\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 38\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/job/query.py:2053\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m \n\u001b[1;32m   1848\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;124;03m        :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2052\u001b[0m query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mquery_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_bar_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_bqstorage_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeography_as_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeography_as_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbool_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mint_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mint_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfloat_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfloat_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstring_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstring_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2064\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_date_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_date_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2068\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_datetime_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2069\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrange_timestamp_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2070\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/table.py:2287\u001b[0m, in \u001b[0;36mRowIterator.to_dataframe\u001b[0;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[1;32m   2053\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2054\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2073\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[1;32m   2074\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2075\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a pandas DataFrame by loading all pages of a query.\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \n\u001b[1;32m   2077\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2285\u001b[0m \n\u001b[1;32m   2286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2287\u001b[0m     \u001b[43m_pandas_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify_pandas_imports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m geography_as_object \u001b[38;5;129;01mand\u001b[39;00m shapely \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_SHAPELY_ERROR)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/bigquery/_pandas_helpers.py:1022\u001b[0m, in \u001b[0;36mverify_pandas_imports\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify_pandas_imports\u001b[39m():\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pandas \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1022\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_PANDAS_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas_import_exception\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m db_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_NO_DB_TYPES_ERROR) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdb_dtypes_import_exception\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Please install the 'pandas' package to use this function."
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client('transfusion-reactions') #put your project id here\n",
    "query = \"\"\"WITH first_admission_time AS\n",
    "(\n",
    "  SELECT\n",
    "      p.subject_id, p.dob, p.gender\n",
    "      , MIN (a.admittime) AS first_admittime\n",
    "      , MIN( DATETIME_DIFF(admittime, dob, YEAR) )\n",
    "          AS first_admit_age\n",
    "  FROM `physionet-data.mimiciii_clinical.patients` p\n",
    "  INNER JOIN `physionet-data.mimiciii_clinical.admissions` a\n",
    "  ON p.subject_id = a.subject_id\n",
    "  GROUP BY p.subject_id, p.dob, p.gender\n",
    "  ORDER BY p.subject_id\n",
    ")\n",
    ", age as\n",
    "(\n",
    "  SELECT\n",
    "      subject_id, dob, gender\n",
    "      , first_admittime, first_admit_age\n",
    "      , CASE\n",
    "          -- all ages > 89 in the database were replaced with 300\n",
    "          WHEN first_admit_age > 89\n",
    "              then '>89'\n",
    "          WHEN first_admit_age >= 14\n",
    "              THEN 'adult'\n",
    "          WHEN first_admit_age <= 1\n",
    "              THEN 'neonate'\n",
    "          ELSE 'middle'\n",
    "          END AS age_group\n",
    "  FROM first_admission_time\n",
    ")\n",
    "select age_group, gender\n",
    "  , count(subject_id) as NumberOfPatients\n",
    "from age\n",
    "group by age_group, gender\"\"\"\n",
    "results = client.query(query).to_dataframe()\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
